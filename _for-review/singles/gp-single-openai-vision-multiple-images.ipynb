{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-YxS6VHJrDIp","executionInfo":{"status":"ok","timestamp":1708099658583,"user_tz":300,"elapsed":6348,"user":{"displayName":"Gonzalo Pelenur","userId":"06533601451551970807"}},"outputId":"68d80490-6e15-46db-b541-22e3d09f0dbc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/226.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/226.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n","Installing collected packages: h11, httpcore, httpx, openai\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 openai-1.12.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iSCurMMBoxBD","executionInfo":{"status":"ok","timestamp":1708104247072,"user_tz":300,"elapsed":18269,"user":{"displayName":"Gonzalo Pelenur","userId":"06533601451551970807"}},"outputId":"3b19b597-1360-4de9-d3af-a86af876c45d"},"outputs":[{"output_type":"stream","name":"stdout","text":["URL option selected\n","The images provided show two different species of bears. \n","\n","The first image depicts a brown bear, identifiable by its thick brown fur, powerful build, and its humped shoulders, which are characteristic of its species.\n","\n","The second image features a giant panda, easily recognized by its distinctive black and white coloration, with black fur around its eyes, ears, and on its limbs, and white fur on the rest of its body.\n","\n","The main differences between these two are their species, appearance, habitat, and diet. The brown bear (Ursus arctos) is one of the most widespread species of bear, found in various habitats across the northern hemisphere, and has an omnivorous diet, which can include fish, small mammals, fruit, and vegetation. \n","\n","On the other hand, the giant panda (Ailuropoda melanoleuca) is native to a few mountain ranges in central China, mainly in Sichuan, and has a diet that is predominantly composed of bamboo, although it is classified as a carnivore due to its digestive system being more suited to processing meat.\n"]}],"source":["# @title Compare Images\n","from google.colab import userdata\n","isURL = False # @param {type:\"boolean\"}\n","prompt = \"What are in these images? Is there any difference between them?\" # @param {type:\"string\"}\n","images = [\"https://upload.wikimedia.org/wikipedia/commons/9/9e/Ours_brun_parcanimalierpyrenees_1.jpg\",\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Grosser_Panda.JPG/1200px-Grosser_Panda.JPG\"] # @param {type:\"raw\"}\n","\n","\n","if isURL:\n","  print(\"URL option selected\")\n","  from openai import OpenAI\n","\n","  client = OpenAI(api_key = userdata.get('OPENAI_API_KEY'))\n","  messages = [\n","      {\n","        \"role\": \"user\",\n","        \"content\": [\n","          {\"type\": \"text\", \"text\": prompt},\n","        ],\n","      }\n","    ]\n","  for image in images:\n","    messages[0][\"content\"].append({\n","        \"type\": \"image_url\",\n","            \"image_url\": image\n","    })\n","  # print(messages)\n","  response = client.chat.completions.create(\n","    model=\"gpt-4-vision-preview\",\n","    messages=messages,\n","    max_tokens=300,\n","  )\n","  print(response.choices[0].message.content)\n","else:\n","  print(\"Image File option selected\")\n","  import base64\n","  import requests\n","\n","  # OpenAI API Key\n","  api_key = userdata.get('OPENAI_API_KEY')\n","\n","  # Function to encode the image\n","  def encode_image(image_path):\n","    with open(image_path, \"rb\") as image_file:\n","      return base64.b64encode(image_file.read()).decode('utf-8')\n","  messages = [{\n","        \"role\": \"user\",\n","        \"content\": [\n","          {\n","            \"type\": \"text\",\n","            \"text\": prompt\n","          }\n","        ]\n","      }]\n","  # Path to your image\n","  for image in images:\n","    image_path = image\n","\n","    # Getting the base64 string\n","    base64_image = encode_image(image_path)\n","    messages[0][\"content\"].append(\n","        {\n","            \"type\": \"image_url\",\n","            \"image_url\": {\n","              \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n","            }\n","          })\n","\n","  headers = {\n","    \"Content-Type\": \"application/json\",\n","    \"Authorization\": f\"Bearer {api_key}\"\n","  }\n","\n","  payload = {\n","    \"model\": \"gpt-4-vision-preview\",\n","    \"messages\": messages,\n","    \"max_tokens\": 300\n","  }\n","\n","  response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n","\n","  print(response.json()[\"choices\"][0][\"message\"][\"content\"])\n","  # print(response.json().choices[0].message.content)"]}]}